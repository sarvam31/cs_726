{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from mo_sql_parsing import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1113, 3242], 'attention_mask': [1, 1]}\n",
      "{'input_ids': [270, 35], 'attention_mask': [1, 1]}\n",
      "{'input_ids': [270, 36, 34], 'attention_mask': [1, 1, 1]}\n",
      "{'input_ids': [270, 36, 34, 34], 'attention_mask': [1, 1, 1, 1]}\n",
      "{'input_ids': [77, 10765, 81, 31590, 79], 'attention_mask': [1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"seeklhy/codes-3b\")\n",
    "\n",
    "print(tokenizer(\"subtree\"))\n",
    "print(tokenizer(\"st1\"))\n",
    "print(tokenizer(\"st20\"))\n",
    "print(tokenizer(\"st200\"))\n",
    "print(tokenizer(\"[LEFT_CHILD]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[NODE_BEGIN]greater than or equal to[NB]st2[NB]st4', '[NODE_BEGIN]equal to[NB]st1[NB]st3', '']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "match() missing 1 required positional argument: 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m foo2 \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[NODE_END\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[NODE_BEGIN]greater than or equal to[NB]st2[NB]st4[NODE_END][NODE_BEGIN]equal to[NB]st1[NB]st3[NODE_END]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(foo2)\n\u001b[0;32m----> 7\u001b[0m bar \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m^\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m[NODE_BEGIN\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m]([a-z ]+)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m[NB\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m](st\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m[NB\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m](st\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m[NODE_END\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m]$\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m bar\u001b[38;5;241m.\u001b[39mgroups():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(j)\n",
      "\u001b[0;31mTypeError\u001b[0m: match() missing 1 required positional argument: 'string'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "foo = \"[NODE_BEGIN]name[NODE_END][NODE_BEGIN]country[NODE_END][NODE_BEGIN]age[NODE_END][NODE_BEGIN]singer[NODE_END]\"\n",
    "\n",
    "foo2 = re.split(r\"\\[NODE_END\\]\", \"[NODE_BEGIN]greater than or equal to[NB]st2[NB]st4[NODE_END][NODE_BEGIN]equal to[NB]st1[NB]st3[NODE_END]\")\n",
    "print(foo2)\n",
    "bar = re.match(r\"^\\[NODE_BEGIN\\]([a-z ]+)\\[NB\\](st\\d+)\\[NB\\](st\\d+)\\[NODE_END\\]$\", )\n",
    "for j in bar.groups():\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = \"[NODE_BEGIN]greater than or equal to[NB]st2[NB]st4[NODE_END][NODE_BEGIN]equal to[NB]st1[NB]st3[NODE_END]\"\n",
    "\n",
    "[(x + \"[NODE_END]\") for x in foo.split(\"[NODE_END]\") if x != \"\"]\n",
    "\n",
    "foo.count(\"[NB]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "operations = [\"union\", \"intersection\", \"difference\", \"selection\", \"cartesian product\", \"projection\", \"and\", \"or\", \"greater than\", \"greater than or equal to\", \"less than\", \"less than or equal to\", \"order by ascending\", \"order by descending\", \"group by\", \"limit\", \"in\", \"not in \", \"like\", \"not like\", \"sum\", \"max\", \"min\", \"count\", \"average\", \"distinct\", \"keep\"]\n",
    "\n",
    "operation_types = [\"predicate\", \"relation\", \"schema_constant\", \"any\"]\n",
    "\n",
    "operations_type_map = { \"union\": \"relation\",\n",
    "                       \"intersection\": \"relation\",\n",
    "                        \"difference\": \"relation\",\n",
    "                        \"selection\": \"relation\",\n",
    "                        \"cartesian product\": \"relation\",\n",
    "                        \"projection\": \"relation\",\n",
    "                        \"and\": \"predicate\",\n",
    "                        \"or\": \"predicate\",\n",
    "                        \"greater than\": \"predicate\",\n",
    "                        \"greater than or equal to\": \"predicate\",\n",
    "                        \"less than\": \"predicate\",\n",
    "                        \"less than or equal to\": \"predicate\",\n",
    "                        \"order by ascending\": \"relation\",\n",
    "                        \"order by descending\": \"relation\",\n",
    "                        \"group by\": \"relation\",\n",
    "                        \"limit\": \"relation\",\n",
    "                        \"in\": \"predicate\",\n",
    "                        \"not in \": \"predicate\",\n",
    "                        \"like\": \"predicate\",\n",
    "                        \"not like\": \"predicate\",\n",
    "                        \"sum\": \"schema_constant\",\n",
    "                        \"max\": \"schema_constant\",\n",
    "                        \"min\": \"schema_constant\",\n",
    "                        \"count\": \"schema_constant\",\n",
    "                        \"average\": \"schema_constant\",\n",
    "                        \"distinct\": \"schema_constant\",\n",
    "                        \"keep\" : \"any\"\n",
    "}\n",
    "\n",
    "print(len(operations))\n",
    "print(len(operations_type_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level 0 node samples = \"[NODE_BEGIN]name[NODE_END][NODE_BEGIN]country[NODE_END][NODE_BEGIN]age[NODE_END][NODE_BEGIN]singer[NODE_END][NODE_BEGIN]60[NODE_END]\"\n",
    "level 1 node samnple = \"[NODE_BEGIN]greater than or equal to[NB]st2[NB]st4[NODE_END]\" #binary\n",
    "level 1 node sample = \"[NODE_BEGIN]keep[NB]st2[NODE_END]\" #unary\n",
    "\n",
    "\n",
    "\n",
    "\"level_wise_subtrees\": [\n",
    "            \\\\name, country, age, singer, 60\n",
    "            \"[NODE_BEGIN]name[NODE_END][NODE_BEGIN]country[NODE_END][NODE_BEGIN]age[NODE_END][NODE_BEGIN]singer[NODE_END][NODE_BEGIN]60[NODE_END]\",\n",
    "            \"[NODE_BEGIN]greater than or equal to[NB]st2[NB]st4[NODE_END][NODE_BEGIN]\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DS = Path('data')\n",
    "PATH_BIRD_SQL = PATH_DS / 'bird'\n",
    "PATH_SPIDER_SQL = PATH_DS / 'spider'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_out_path = lambda path, suffix: path.parent / ''.join(path.parts[-1].split('.')[:-1] + [suffix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    PATH_SPIDER_SQL / \"processed\" / \"dev_gold.json\",\n",
    "    PATH_SPIDER_SQL / \"processed\" / \"train_gold.json\",\n",
    "    PATH_BIRD_SQL / \"dev\" / \"dev.json\",\n",
    "    PATH_BIRD_SQL / \"train\" / \"train.json\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sql(df, key=\"SQL\"):\n",
    "    errors = []\n",
    "    df['SQL_parse'] = None\n",
    "    for i in range(df.shape[0]):\n",
    "        try:\n",
    "            df.at[i, 'SQL_parse'] = parse(df.at[i, key])\n",
    "        except Exception as e:\n",
    "            errors.append(i)\n",
    "    return df, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sql_parse(path: Path):\n",
    "    with open(path) as f:\n",
    "        df = pd.DataFrame(json.load(f))\n",
    "        df.set_index(\"question_id\", inplace=True)\n",
    "    df, errors = parse_sql(df)\n",
    "    out_path = generate_out_path(path, \"_parse.json\")\n",
    "    df.to_json(out_path, orient=\"records\", indent=4)\n",
    "    if len(errors) > 0:\n",
    "        with open(generate_out_path(path, \"_parse_errors.json\"), \"w\") as f:\n",
    "            json.dump(errors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sql(df):\n",
    "    df_sql = df[\"SQL\"].copy()\n",
    "\n",
    "    # remove queries with inner joins and nested queries\n",
    "    df_sql = df_sql[~df_sql.str.contains(\"inner join\", case=False)]\n",
    "    df_sql = df_sql[~df_sql.str.contains(r\"\\(.*\\bSELECT\\b.*\\)\", regex=True, case=False)]\n",
    "\n",
    "    # TODO: add filter number of tokens < 55\n",
    "\n",
    "    return df.loc[df_sql.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(949, 3)\n",
      "(6464, 3)\n",
      "(336, 5)\n",
      "(1984, 4)\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    with open(path) as f:\n",
    "        df = pd.DataFrame(json.load(f))\n",
    "        if \"question_id\" not in df.columns:\n",
    "            df[\"question_id\"] = df.index\n",
    "        df.set_index(\"question_id\", inplace=True)\n",
    "        df = filter_sql(df)\n",
    "        out_path = generate_out_path(path, \"_filtered.json\")\n",
    "        df.to_json(out_path, orient=\"records\", indent=4)\n",
    "        print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
